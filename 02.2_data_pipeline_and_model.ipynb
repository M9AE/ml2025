{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03aa00a0",
   "metadata": {},
   "source": [
    "# Notebook de préparation des données et modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2065f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# import lightgbm as lgb\n",
    "# import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3989f3d",
   "metadata": {},
   "source": [
    "todo\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b2abab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filepath_or_buffer=\"./data/train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8f037",
   "metadata": {},
   "source": [
    "Ce notebook se divise en trois parties : \n",
    "* Mise en place d'une pipeline de transformation des données\n",
    "* Sélection d'un modèle \n",
    "* Optimisation des paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2837065d",
   "metadata": {},
   "source": [
    "## I. Mise en place d'une pipeline de transformation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22ed43",
   "metadata": {},
   "source": [
    "#### a. préparation sur les features explicites (N colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d38c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_url(url):\n",
    "    if not isinstance(url, str):\n",
    "        return (np.nan, np.nan)\n",
    "\n",
    "    url = url[7:-1]\n",
    "    url_split = url.split(\".\")\n",
    "    radical = url_split[0]\n",
    "    extension = \".\".join(url_split[1:])\n",
    "    return (radical, extension)\n",
    "\n",
    "\n",
    "def explicit_part_preparation(df):\n",
    "    # drops\n",
    "    df = (\n",
    "        df\n",
    "        .query(\"followers > 0 & word_count > 0\")\n",
    "        .drop(columns=[\"language\", \"author\", \"is_retweet\"])\n",
    "    )\n",
    "\n",
    "    # shared_url_domain\n",
    "    shared_url_split_df = df[\"shared_url_domain\"].apply(split_url).apply(pd.Series)\n",
    "\n",
    "    # shared_url_domain: Radical\n",
    "    radical_freq_series = shared_url_split_df[0].value_counts()\n",
    "    shared_url_split_df[0] = shared_url_split_df[0].map(lambda x: x if (radical_freq_series.get(x, 3) > 2) else \"other\")\n",
    "\n",
    "    # shared_url_domain: Extension\n",
    "    extension_freq_series = shared_url_split_df[1].value_counts()\n",
    "    shared_url_split_df[1] = shared_url_split_df[1].map(lambda x: x if (extension_freq_series.get(x, 1) > 1) else \"other\")\n",
    "\n",
    "    # shared_url_domain: Encoding\n",
    "    df[[\"shared_url_radical\", \"shared_url_extension\"]] = shared_url_split_df\n",
    "    df_encoded = pd.get_dummies(df, columns=[\"shared_url_radical\", \"shared_url_extension\"])\n",
    "\n",
    "    # shared_url_count\n",
    "    df_encoded[\"is_shared_url\"] = df_encoded[\"shared_url_count\"] > 0\n",
    "\n",
    "    # timestamp\n",
    "    timestamp_datetime_series = pd.to_datetime(df_encoded[\"timestamp\"], unit='ms')\n",
    "\n",
    "    df_encoded[\"month_post\"] = timestamp_datetime_series.dt.month\n",
    "    df_encoded[\"day_of_week_post\"] = timestamp_datetime_series.dt.dayofweek\n",
    "    df_encoded[\"hour_post\"] = timestamp_datetime_series.dt.hour\n",
    "\n",
    "    max_timestamp = df_encoded[\"timestamp\"].max()\n",
    "    df_encoded[\"timestamp\"] = df_encoded[\"timestamp\"].apply(lambda x: np.log10(max_timestamp + 1 - x)).replace(-np.inf, 0)\n",
    "\n",
    "    # word_count, engagement, followers\n",
    "    df_encoded[\"word_count\"] = df_encoded[\"word_count\"].apply(lambda x: np.log10(x+1))\n",
    "    df_encoded[\"engagement\"] = df_encoded[\"engagement\"].apply(np.log10).replace(-np.inf, 0)\n",
    "    df_encoded[\"followers\"] = df_encoded[\"followers\"].apply(np.log10)\n",
    "\n",
    "    # feature1\n",
    "    max_feature1 = df_encoded[\"feature1\"].max()\n",
    "    df_encoded[\"feature1_is_max\"] = df_encoded[\"feature1\"] == max_feature1\n",
    "\n",
    "    # final drops\n",
    "    df_encoded.drop(columns=[\"feature1\", \"shared_url_count\", \"shared_url_domain\"], inplace=True)\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8b612",
   "metadata": {},
   "source": [
    "#### b. préparation sur les features embedded (M colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02cd6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def implicit_part_preparation(df):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
