{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c66f4d3",
   "metadata": {},
   "source": [
    "Jusqu'à présent, je me suis concentré sur le fichier train.csv mais il y a aussi authorData qui n'a juste pas l'embedding.\n",
    "\n",
    "J'avais vu que l'embedding n'était pas méga importante mais je vais chercher à la garder. Pour cela, je vais chercher à estimer lesparamètres de l'embedding.\n",
    "\n",
    "(Notations : D1 = train.csv; D2 = authorData.csv; N = colonnes non-embedding(=explicites parce que je les connais presque qu'elles sont presques lisibles par un humain); M = colonnes embeddées.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d82280",
   "metadata": {},
   "source": [
    "idée : utiliser train pour apprendre l'embedding sur N colonnes pour en prédire m<=M.\n",
    "M=1024 donc prédire les 1024 est violent. On se propose de prédire les m termes de la pca\n",
    "\n",
    "Etapes (d'entrainement et calibration du modèle)\n",
    "* PCA(m) sur M colonnes de train\n",
    "* diff train, test et X, Y \n",
    "* prédiction(m) à partir de N de X_train\n",
    "  * modèle\n",
    "  * métrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f4614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "\n",
    "from notebook_helper import explicit_part_preparation, explicit_part_transform_from_processed_model, pca_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639e8553",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/train.csv\", sep=\",\")\n",
    "df2 = pd.read_csv(\"./data/authorData.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ec0b4c",
   "metadata": {},
   "source": [
    "### a. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d5d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 20\n",
    "df1_reduced = pca_transform(df1, n_components=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "020c4cab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engagement</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>language</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>followers</th>\n",
       "      <th>author</th>\n",
       "      <th>word_count</th>\n",
       "      <th>shared_url_count</th>\n",
       "      <th>shared_url_domain</th>\n",
       "      <th>...</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1655784230254</td>\n",
       "      <td>en</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>696</td>\n",
       "      <td>bd20432d80dfe4825a7a106312bda52e</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009567</td>\n",
       "      <td>-0.125106</td>\n",
       "      <td>0.033840</td>\n",
       "      <td>0.020685</td>\n",
       "      <td>-0.051285</td>\n",
       "      <td>-0.001273</td>\n",
       "      <td>-0.021936</td>\n",
       "      <td>0.047203</td>\n",
       "      <td>-0.027051</td>\n",
       "      <td>-0.038264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91007</td>\n",
       "      <td>1655599613254</td>\n",
       "      <td>en</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>17526</td>\n",
       "      <td>71e2ecc6cc1d6515a6b122fab4c63bfc</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098711</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>0.018272</td>\n",
       "      <td>0.008464</td>\n",
       "      <td>-0.063585</td>\n",
       "      <td>-0.009290</td>\n",
       "      <td>0.011504</td>\n",
       "      <td>0.089991</td>\n",
       "      <td>-0.043554</td>\n",
       "      <td>0.025581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1655788872254</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>239</td>\n",
       "      <td>2a9109f38d90a2a96e284a07c1a57e9b</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026528</td>\n",
       "      <td>-0.009448</td>\n",
       "      <td>0.066015</td>\n",
       "      <td>-0.002279</td>\n",
       "      <td>-0.005414</td>\n",
       "      <td>-0.017258</td>\n",
       "      <td>-0.010806</td>\n",
       "      <td>-0.032932</td>\n",
       "      <td>-0.051068</td>\n",
       "      <td>-0.004298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   engagement      timestamp language  feature1  feature2  followers  \\\n",
       "0          15  1655784230254       en        73         0        696   \n",
       "1       91007  1655599613254       en       100         5      17526   \n",
       "2           3  1655788872254       en         0        -5        239   \n",
       "\n",
       "                             author  word_count  shared_url_count  \\\n",
       "0  bd20432d80dfe4825a7a106312bda52e          18                 0   \n",
       "1  71e2ecc6cc1d6515a6b122fab4c63bfc          15                 0   \n",
       "2  2a9109f38d90a2a96e284a07c1a57e9b           8                 0   \n",
       "\n",
       "  shared_url_domain  ...       V11       V12       V13       V14       V15  \\\n",
       "0               NaN  ... -0.009567 -0.125106  0.033840  0.020685 -0.051285   \n",
       "1               NaN  ... -0.098711  0.001065  0.018272  0.008464 -0.063585   \n",
       "2               NaN  ... -0.026528 -0.009448  0.066015 -0.002279 -0.005414   \n",
       "\n",
       "        V16       V17       V18       V19       V20  \n",
       "0 -0.001273 -0.021936  0.047203 -0.027051 -0.038264  \n",
       "1 -0.009290  0.011504  0.089991 -0.043554  0.025581  \n",
       "2 -0.017258 -0.010806 -0.032932 -0.051068 -0.004298  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_reduced.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edacad53",
   "metadata": {},
   "source": [
    "### b. préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304cccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_prepared, preparation_model = explicit_part_preparation(df1_reduced)\n",
    "df2_prepared = explicit_part_transform_from_processed_model(df2, preparation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8e8965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engagement</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>feature2</th>\n",
       "      <th>followers</th>\n",
       "      <th>word_count</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>contains_video</th>\n",
       "      <th>contains_image</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>...</th>\n",
       "      <th>shared_url_extension_net</th>\n",
       "      <th>shared_url_extension_news</th>\n",
       "      <th>shared_url_extension_org</th>\n",
       "      <th>shared_url_extension_other</th>\n",
       "      <th>shared_url_extension_tv</th>\n",
       "      <th>is_shared_url</th>\n",
       "      <th>month_post</th>\n",
       "      <th>day_of_week_post</th>\n",
       "      <th>hour_post</th>\n",
       "      <th>feature1_is_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.176091</td>\n",
       "      <td>6.727053</td>\n",
       "      <td>0</td>\n",
       "      <td>2.842609</td>\n",
       "      <td>1.278754</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.040117</td>\n",
       "      <td>0.039279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.959075</td>\n",
       "      <td>8.278642</td>\n",
       "      <td>5</td>\n",
       "      <td>4.243683</td>\n",
       "      <td>1.204120</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.154545</td>\n",
       "      <td>0.130231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.477121</td>\n",
       "      <td>5.840107</td>\n",
       "      <td>-5</td>\n",
       "      <td>2.378398</td>\n",
       "      <td>0.954243</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.319861</td>\n",
       "      <td>-0.050030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   engagement  timestamp  feature2  followers  word_count  is_reply  \\\n",
       "0    1.176091   6.727053         0   2.842609    1.278754     False   \n",
       "1    4.959075   8.278642         5   4.243683    1.204120     False   \n",
       "2    0.477121   5.840107        -5   2.378398    0.954243      True   \n",
       "\n",
       "   contains_video  contains_image        V1        V2  ...  \\\n",
       "0           False            True  0.040117  0.039279  ...   \n",
       "1           False           False -0.154545  0.130231  ...   \n",
       "2           False           False  0.319861 -0.050030  ...   \n",
       "\n",
       "   shared_url_extension_net  shared_url_extension_news  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "\n",
       "   shared_url_extension_org  shared_url_extension_other  \\\n",
       "0                       0.0                         1.0   \n",
       "1                       0.0                         1.0   \n",
       "2                       0.0                         1.0   \n",
       "\n",
       "   shared_url_extension_tv  is_shared_url  month_post  day_of_week_post  \\\n",
       "0                      0.0          False           6                 1   \n",
       "1                      0.0          False           6                 6   \n",
       "2                      0.0          False           6                 1   \n",
       "\n",
       "   hour_post  feature1_is_max  \n",
       "0          4            False  \n",
       "1          0             True  \n",
       "2          5            False  \n",
       "\n",
       "[3 rows x 69 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_prepared.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f85afac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engagement</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>feature2</th>\n",
       "      <th>followers</th>\n",
       "      <th>word_count</th>\n",
       "      <th>is_reply</th>\n",
       "      <th>contains_video</th>\n",
       "      <th>contains_image</th>\n",
       "      <th>shared_url_radical_amazon</th>\n",
       "      <th>shared_url_radical_breitbart</th>\n",
       "      <th>...</th>\n",
       "      <th>shared_url_extension_net</th>\n",
       "      <th>shared_url_extension_news</th>\n",
       "      <th>shared_url_extension_org</th>\n",
       "      <th>shared_url_extension_other</th>\n",
       "      <th>shared_url_extension_tv</th>\n",
       "      <th>is_shared_url</th>\n",
       "      <th>month_post</th>\n",
       "      <th>day_of_week_post</th>\n",
       "      <th>hour_post</th>\n",
       "      <th>feature1_is_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.881288</td>\n",
       "      <td>0</td>\n",
       "      <td>2.999565</td>\n",
       "      <td>1.414973</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.666555</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.542327</td>\n",
       "      <td>8.595291</td>\n",
       "      <td>-5</td>\n",
       "      <td>5.657622</td>\n",
       "      <td>1.662758</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   engagement  timestamp  feature2  followers  word_count  is_reply  \\\n",
       "0    0.000000   7.881288         0   2.999565    1.414973     False   \n",
       "1    0.000000   7.666555        -5   0.698970    1.000000     False   \n",
       "2    3.542327   8.595291        -5   5.657622    1.662758     False   \n",
       "\n",
       "   contains_video  contains_image  shared_url_radical_amazon  \\\n",
       "0            True           False                        0.0   \n",
       "1           False           False                        0.0   \n",
       "2           False           False                        0.0   \n",
       "\n",
       "   shared_url_radical_breitbart  ...  shared_url_extension_net  \\\n",
       "0                           0.0  ...                       0.0   \n",
       "1                           0.0  ...                       0.0   \n",
       "2                           0.0  ...                       0.0   \n",
       "\n",
       "   shared_url_extension_news  shared_url_extension_org  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "\n",
       "   shared_url_extension_other  shared_url_extension_tv  is_shared_url  \\\n",
       "0                         1.0                      0.0          False   \n",
       "1                         1.0                      0.0          False   \n",
       "2                         1.0                      0.0          False   \n",
       "\n",
       "   month_post  day_of_week_post  hour_post  feature1_is_max  \n",
       "0           6                 0          8             True  \n",
       "1           6                 0         16             True  \n",
       "2           6                 3         16             True  \n",
       "\n",
       "[3 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2_prepared.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0def8f",
   "metadata": {},
   "source": [
    "### c. entraînement N->m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac9c603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 891\n",
      "[LightGBM] [Info] Number of data points in the train set: 4150, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mathi\\dev\\ml2025\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "V_cols = [col for col in df1_prepared.columns if \"V\" in col]\n",
    "\n",
    "# Separation of the target\n",
    "X = df1_prepared.drop(columns=V_cols)\n",
    "y = df1_prepared[V_cols]\n",
    "\n",
    "# Normalisation\n",
    "sc_X, sc_y = StandardScaler(), StandardScaler()\n",
    "X_train, y_train = sc_X.fit_transform(X), sc_y.fit_transform(y)\n",
    "X_eval = sc_X.transform(df2_prepared)\n",
    "\n",
    "# Model training\n",
    "base = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "model = MultiOutputRegressor(base)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "764bcaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_completed = pd.concat(\n",
    "    [\n",
    "        df2_prepared.reset_index(drop=True),\n",
    "        pd.DataFrame(y_pred, columns=V_cols)\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88d28a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626063 lignes après préparation\n",
      "629877 lignes avant préparation.\n",
      "On en a perdu 3814\n",
      "On a retiré 3814 outliers et \n",
      "df2_completed.shape[0] + nb_cols_outliers_followers_and_word_count = 626063 + 3814 = 629877 = 629877\n"
     ]
    }
   ],
   "source": [
    "nb_cols_difference_after_preparation = df2.shape[0] - df2_completed.shape[0]\n",
    "nb_cols_outliers_followers_and_word_count = df2.query(\"followers == 0 or word_count == 0\").shape[0]\n",
    "\n",
    "print(\n",
    "    f\"{df2_completed.shape[0]} lignes après préparation\\n{df2.shape[0]} lignes \"\n",
    "    f\"avant préparation.\\nOn en a perdu {nb_cols_difference_after_preparation}\\n\"\n",
    "    f\"On a retiré {nb_cols_outliers_followers_and_word_count} outliers et \\n\"\n",
    "    f\"df2_completed.shape[0] + nb_cols_outliers_followers_and_word_count = {df2_completed.shape[0]} + {nb_cols_outliers_followers_and_word_count} = {df2_completed.shape[0] + nb_cols_outliers_followers_and_word_count}\"\n",
    "    f\" {\"=\" * (df2_completed.shape[0] + nb_cols_outliers_followers_and_word_count == df2.shape[0]) + \"≠\" * (df2_completed.shape[0] + nb_cols_outliers_followers_and_word_count != df2.shape[0])} \"\n",
    "    f\"{df2.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b850507",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_prepared.to_pickle(\"./data/train_d1.pickle\")\n",
    "df2_completed.to_pickle(\"./data/train_d2.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
